---
sidebar_position: 3
---


# robots.txt
Robots.txt是一个文本文件，用于告诉搜索引擎爬虫如何访问和抓取网站的内容。它位于网站的根目录下，通过指定特定的规则来控制搜索引擎爬虫的行为。

Robots.txt文件允许网站管理员指定哪些页面可以被搜索引擎爬取，以及哪些页面应该被忽略。
它的作用是帮助搜索引擎了解网站的结构，并根据指令来决定是否抓取和索引特定页面。

以下是一个简单的Robots.txt文件的示例：
```txt title="public/robots.txt"
User-agent: *
Disallow: /admin/
Disallow: /private/
Allow: /public/

Sitemap: https://example.com/sitemap.xml
```
robots.txt文件一般放在 `public` 目录下，打包后可以直接通过URL访问。

在上面的示例中，
- User-agent: *表示适用于所有搜索引擎爬虫。
- Disallow指令用于指定不希望搜索引擎抓取的页面或目录，例如/admin/和/private/。
- Allow指令用于指定允许搜索引擎抓取的页面或目录，例如/public/。

Robots.txt文件还可以包含其他指令，并且可以针对不同的搜索引擎爬虫指定不同的规则。
此外，文件中可以包含一个或多个Sitemap指令，用于指定网站的Sitemap文件的URL，帮助搜索引擎发现和索引网站的内容。

需要注意的是，robots.txt文件仅作为一个建议，而不是强制性规则。一些搜索引擎爬虫可能会尊重Robots.txt文件，但也有一些爬虫会忽略它。
因此，敏感信息或重要内容不应仅依赖于Robots.txt文件来保护，建议使用其他措施来确保其安全性。